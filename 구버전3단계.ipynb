{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43759333",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1차_test.feather\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m로딩 완료.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --- 3. 시간 관련 특성 생성 ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wch23\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\feather_format.py:112\u001b[39m, in \u001b[36mread_feather\u001b[39m\u001b[34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03mLoad a feather-format object from the file path.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    109\u001b[39m \u001b[33;03m>>> df = pd.read_feather(\"path/to/file.feather\")  # doctest: +SKIP\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feather\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wch23\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyarrow\\feather.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (Codec, Table,  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m     24\u001b[39m                          concat_tables, schema)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mext\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _feather\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_feather\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FeatherError  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFeatherDataset\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib \n",
    "\n",
    "df = pd.read_feather('1차_test.feather')\n",
    "print(\"로딩 완료.\")\n",
    "\n",
    "# --- 3. 시간 관련 특성 생성 ---\n",
    "print(\"U/V 벡터에서 wind_spd (풍속) 값을 역산합니다...\")\n",
    "if 'U_a' in df.columns and 'V_a' in df.columns:\n",
    "    df['wind_spd_a'] = np.sqrt(df['U_a']**2 + df['V_a']**2)\n",
    "if 'U_b' in df.columns and 'V_b' in df.columns:\n",
    "    df['wind_spd_b'] = np.sqrt(df['U_b']**2 + df['V_b']**2)\n",
    "print(\"풍속 역산 완료.\")\n",
    "\n",
    "print(\"시간 관련 특성을 생성합니다...\")\n",
    "df['minute'] = df['time'].dt.minute\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['decimal_hour'] = df['hour'] + (df['minute'] / 60.0)\n",
    "df['day_of_year'] = df['time'].dt.dayofyear\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['decimal_hour'] / 24.0)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['decimal_hour'] / 24.0)\n",
    "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "df['seasonal_hour'] = df['day_of_year_sin'] * df['hour_sin']\n",
    "\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "# [수정된 섹션 3] 2-Cluster 전략 (Location + Climate) 적용\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "\n",
    "print(\"위치 좌표(coord)와 '평균 기후'를 기반으로 2개의 '스마트 클러스터'를 적용합니다...\")\n",
    "\n",
    "# 3-1. 프로필 테이블 생성 (Test 데이터 기준, nins 없음)\n",
    "print(\"각 발전소의 1년 평균 기후(temp, humidity)를 계산합니다...\")\n",
    "pv_id_stats = df.groupby('pv_id')[['temp_a', 'humidity', 'wind_spd_a', 'pressure', 'vis']].mean().reset_index()\n",
    "pv_id_stats.rename(columns={\n",
    "    'temp_a': 'avg_temp',\n",
    "    'humidity': 'avg_humidity',\n",
    "    'wind_spd_a': 'avg_wind',\n",
    "    'pressure': 'avg_pressure',\n",
    "    'vis': 'avg_vis'\n",
    "}, inplace=True)\n",
    "\n",
    "# 3-2. KMeans 재료 테이블 생성\n",
    "unique_locations = df[['pv_id', 'coord1', 'coord2']].drop_duplicates(subset=['pv_id'])\n",
    "unique_locations = pd.merge(unique_locations, pv_id_stats, on='pv_id', how='left')\n",
    "\n",
    "# 3-3. ★ (수정) ★ 2개의 특성 리스트 정의 (Train과 동일)\n",
    "cluster_features_LOC = ['coord1', 'coord2'] # (지리 군집용)\n",
    "\n",
    "cluster_features_CLIMATE = [ # (기후 군집용)\n",
    "    'avg_temp', 'avg_humidity',\n",
    "    'avg_wind', 'avg_pressure', 'avg_vis'\n",
    "]\n",
    "all_cluster_features = cluster_features_LOC + cluster_features_CLIMATE\n",
    "\n",
    "# 3-4. 결측치 처리 (fillna는 if/else 밖에서 실행)\n",
    "nan_check = unique_locations[all_cluster_features].isnull()\n",
    "if nan_check.any().any():\n",
    "    print(\"\\n!! 경고: Test KMeans 재료에서 결측치가 발견되었습니다!!\")\n",
    "    nan_counts_per_column = nan_check.sum()\n",
    "    print(nan_counts_per_column[nan_counts_per_column > 0])\n",
    "else:\n",
    "    print(\"Test KMeans 군집 재료에 결측치가 없는 것을 확인했습니다.\")\n",
    "    \n",
    "unique_locations[all_cluster_features] = unique_locations[all_cluster_features].fillna(0)\n",
    "print(\"결측치 .fillna(0) 처리 완료.\")\n",
    "\n",
    "\n",
    "# 3-5. ★ (수정) ★ Cluster 1: Location Cluster (지리 군집) 적용\n",
    "print(\"저장된 (scaler_loc)와 (kmeans_loc) 모델을 불러옵니다...\")\n",
    "scaler_loc = joblib.load('kmeans_scaler_loc.joblib')\n",
    "kmeans_loc = joblib.load('kmeans_model_loc.joblib')\n",
    "\n",
    "print(\"'location_cluster' (지리 군집)을 예측합니다...\")\n",
    "scaled_features_loc = scaler_loc.transform(unique_locations[cluster_features_LOC])\n",
    "kmeans_loc.cluster_centers_ = kmeans_loc.cluster_centers_.astype(np.float64)\n",
    "scaled_features_loc_64 = scaled_features_loc.astype(np.float64)\n",
    "unique_locations['location_cluster'] = kmeans_loc.predict(scaled_features_loc_64)\n",
    "\n",
    "\n",
    "# 3-6. ★ (수정) ★ Cluster 2: Climate Cluster (기후 군집) 적용\n",
    "print(\"저장된 (scaler_climate)와 (kmeans_climate) 모델을 불러옵니다...\")\n",
    "scaler_climate = joblib.load('kmeans_scaler_climate.joblib')\n",
    "kmeans_climate = joblib.load('kmeans_model_climate.joblib')\n",
    "\n",
    "print(\"'climate_cluster' (기후 군집)을 예측합니다...\")\n",
    "scaled_features_climate = scaler_climate.transform(unique_locations[cluster_features_CLIMATE])\n",
    "kmeans_climate.cluster_centers_ = kmeans_climate.cluster_centers_.astype(np.float64)\n",
    "scaled_features_climate_64 = scaled_features_climate.astype(np.float64)\n",
    "unique_locations['climate_cluster'] = kmeans_climate.predict(scaled_features_climate_64)\n",
    "\n",
    "\n",
    "# 3-7. ★ (수정) ★ 2개의 '맵' 적용\n",
    "print(\"메모리 효율적인 'cluster_map' 2종을 생성합니다...\")\n",
    "cluster_map_LOC = unique_locations.set_index('pv_id')['location_cluster']\n",
    "cluster_map_CLIMATE = unique_locations.set_index('pv_id')['climate_cluster']\n",
    "\n",
    "print(\".map()을 사용하여 'location_cluster'와 'climate_cluster' 열을 추가합니다...\")\n",
    "df['location_cluster'] = df['pv_id'].map(cluster_map_LOC)\n",
    "df['climate_cluster'] = df['pv_id'].map(cluster_map_CLIMATE) # (신규)\n",
    "\n",
    "df['location_cluster'] = df['location_cluster'].astype('category')\n",
    "df['climate_cluster'] = df['climate_cluster'].astype('category') # (신규)\n",
    "print(\"위치/기후 군집 매핑 완료.\")\n",
    "\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "# [수정된 섹션 4] '맵' 파일 2종 적용 (각각 다른 군집 기준)\n",
    "\n",
    "\n",
    "print(\"클러스터별 '개인화 일출/일몰 맵'을 불러옵니다 (location_cluster 기준)...\")\n",
    "try:\n",
    "    cluster_times = pd.read_csv('cluster_sun_times_map.csv')\n",
    "    sunrise_map = cluster_times.set_index('location_cluster')['sunrise_decimal']\n",
    "    sunset_map = cluster_times.set_index('location_cluster')['sunset_decimal']\n",
    "    \n",
    "    # ★ (수정) ★ 'location_cluster' (지리 군집) 기준으로 맵핑\n",
    "    df['sunrise_decimal'] = df['location_cluster'].map(sunrise_map)\n",
    "    df['sunset_decimal'] = df['location_cluster'].map(sunset_map)\n",
    "    print(\"일출/일몰 맵 병합 완료.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"경고: 'cluster_sun_times_map.csv' 파일을 찾을 수 없습니다.\")\n",
    "    df['sunrise_decimal'] = 0\n",
    "    df['sunset_decimal'] = 0\n",
    "\n",
    "print(\"GroupBy 개인화 기준선 맵 불러오는 중 (climate_cluster 기준)...\")\n",
    "try:\n",
    "    base_df = pd.read_csv('cluster_hour_means_map.csv')\n",
    "    \n",
    "    # ★ (수정) ★ 'climate_cluster' (기후 군집) 기준으로 병합\n",
    "    df = pd.merge(df, base_df, on=['climate_cluster', 'hour'], how='left')\n",
    "    print(\"개인화 기준선 맵 병합 완료.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"경고: 'cluster_hour_means_map.csv' 파일을 찾을 수 없습니다.\")\n",
    "    # (Anomaly 기준열 7개 0으로 채우기)\n",
    "    df['cluster_hour_cloud_mean'] = 0\n",
    "    df['cluster_hour_uv_mean'] = 0\n",
    "    df['cluster_hour_temp_mean'] = 0\n",
    "    df['cluster_hour_humidity_mean'] = 0\n",
    "    df['cluster_hour_vis_mean'] = 0\n",
    "    df['cluster_hour_wind_mean'] = 0\n",
    "    df['cluster_hour_pressure_mean'] = 0\n",
    "\n",
    "# ★★★ (필수) ★★★ Rolling/Lag 계산 전, 시간 순서로 재정렬\n",
    "print(\"Rolling/Lag 특성 생성을 위해 DataFrame을 재정렬합니다...\")\n",
    "df.sort_values(by=['pv_id', 'time'], inplace=True)\n",
    "\n",
    "print(\"'평소 대비 이상 기후' (Anomaly) 특징 생성 중...\")\n",
    "# (Anomaly 계산 로직은 동일)\n",
    "epsilon = 1e-6\n",
    "df['cloud_anomaly'] = df['cloud_a'] / (df['cluster_hour_cloud_mean'] + epsilon)\n",
    "df['uv_anomaly'] = df['uv_idx'] / (df['cluster_hour_uv_mean'] + epsilon)\n",
    "df['temp_anomaly'] = df['temp_a'] / (df['cluster_hour_temp_mean'] + epsilon)\n",
    "df['humidity_anomaly'] = df['humidity'] / (df['cluster_hour_humidity_mean'] +epsilon) \n",
    "df['vis_anomaly'] = df['vis'] / (df['cluster_hour_vis_mean']+epsilon)\n",
    "df['wind_anomaly'] = df['wind_spd_a'] / (df['cluster_hour_wind_mean']+epsilon)\n",
    "df['pressure_anomaly'] = df['pressure'] / (df['cluster_hour_pressure_mean']+epsilon)\n",
    "\n",
    "\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "# [수정된 섹션 5] (섹션 5는 수정할 내용이 없습니다)\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "\n",
    "print(\"이론적 태양광 강도 (Daylight Cosine) 특성을 생성합니다...\")\n",
    "# (수정 없음) 'sunrise_decimal' 값은 이미 'location_cluster' 기준으로 올바르게 매핑됨\n",
    "df['sunrise_decimal'] = df['sunrise_decimal'].astype(np.float32).fillna(4.5)\n",
    "df['sunset_decimal'] = df['sunset_decimal'].astype(np.float32).fillna(20.5)\n",
    "\n",
    "daylight_duration = df['sunset_decimal'] - df['sunrise_decimal']\n",
    "solar_noon = df['sunrise_decimal'] + (daylight_duration / 2.0)\n",
    "scaled_time = (df['decimal_hour'] - solar_noon) * np.pi / daylight_duration\n",
    "df['daylight_cosine'] = np.cos(scaled_time)\n",
    "\n",
    "df.loc[\n",
    "    (df['decimal_hour'] < df['sunrise_decimal']) | \n",
    "    (df['decimal_hour'] > df['sunset_decimal']), \n",
    "    'daylight_cosine'\n",
    "] = 0\n",
    "df.loc[df['daylight_cosine'] < 0, 'daylight_cosine'] = 0\n",
    "print(\"Daylight Cosine 특성 생성 완료.\")\n",
    "\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "# [수정/교체] --- 날씨 '추세' 특성 생성 (15분, 30분, 1시간) ---\n",
    "# ★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★★\n",
    "print(\"날씨 추세(Rolling/Lag/Std) 특성 생성 중...\")\n",
    "\n",
    "# (sort_values가 이미 위에서 실행되었으므로 여기서는 g = df.groupby('pv_id')만 실행)\n",
    "g = df.groupby('pv_id')\n",
    "\n",
    "# 1. 적용할 주요 날씨 특성 정의\n",
    "weather_cols = ['cloud_a', 'temp_a', 'uv_idx', 'pressure', 'humidity']\n",
    "\n",
    "# 2. 적용할 시간 윈도우 정의 (5분 단위)\n",
    "windows = [3, 6, 12] # (15분, 30분, 1시간)\n",
    "\n",
    "print(f\" {len(weather_cols)}개 변수에 대해 {windows} 윈도우 Lag/Rolling/Std 특성을 생성합니다.\")\n",
    "\n",
    "for col in weather_cols:\n",
    "    for w in windows:\n",
    "        df[f'{col}_lag_{w}'] = g[col].shift(w)\n",
    "        df[f'{col}_rolling_{w}_mean'] = g[col].shift(1).rolling(w, min_periods=1).mean()\n",
    "        df[f'{col}_rolling_{w}_std'] = g[col].shift(1).rolling(w, min_periods=1).std()\n",
    "        df[f'{col}_diff_{w}'] = g[col].diff(w)\n",
    "        df[f'{col}_ewm_{w}_mean'] = g[col].shift(1).ewm(span=w, min_periods=1).mean()\n",
    "\n",
    "print(\"다양한 시간대의 Rolling/Lag/Std 특성 생성 완료.\")\n",
    "\n",
    "# --- 기타 차이 및 물리 기반 특성 생성 ---\n",
    "print(\"기타 차이 및 물리 기반 특성 생성 중...\")\n",
    "df['is_precipitating'] = ((df['precip_1h'] > 0) | (df['rain'] > 0) | (df['snow'] > 0)).astype(int)\n",
    "df['station_temp_diff'] = df['temp_b'] - df['temp_a']\n",
    "df['station_cloud_diff'] = df['cloud_a'] - df['cloud_b']\n",
    "df['station_wind_spd_diff'] = df['wind_spd_a'] - df['wind_spd_b']\n",
    "\n",
    "print(\"물리/풍향/상호작용 특성 (is_foggy, wind_power, _x_hour 등)을 생성합니다...\")\n",
    "df['temp_a_sq'] = df['temp_a']**2\n",
    "df['uv_idx_sq'] = df['uv_idx']**2\n",
    "df['sun_exposure_factor'] = df['real_feel_temp'].values - df['real_feel_temp_shade'].values\n",
    "df['diurnal_temp_range'] = df['temp_max'].values - df['temp_min'].values\n",
    "df['saturation_deficit'] = df['temp_a'].values - df['dew_point'].values \n",
    "df['is_foggy'] = (df['vis'] < 1).astype(int)\n",
    "df['wind_power_a'] = df['wind_spd_a'] ** 3\n",
    "df['wind_power_b'] = df['wind_spd_b'] ** 3\n",
    "df['temp_x_hour'] = df['temp_a'] * df['hour_cos']\n",
    "df['cloud_x_hour'] = df['cloud_a'] * df['hour_cos']\n",
    "df['uv_idx_x_hour'] = df['uv_idx'] * df['hour_cos']\n",
    "df['humidity_x_hour'] = df['humidity'] * df['hour_cos']\n",
    "gc.collect()\n",
    "\n",
    "# --- 최종 결측치 처리 (fillna) ---\n",
    "print(\"최종 결측치 처리 (fillna) 중...\")\n",
    "lag_rolling_cols = [col for col in df.columns if '_lag_' in col or '_rolling_' in col]\n",
    "df[lag_rolling_cols] = df[lag_rolling_cols].fillna(-999)\n",
    "\n",
    "if 'is_precipitating' in df.columns:\n",
    "     df['is_precipitating'] = df['is_precipitating'].fillna(-999)\n",
    "if 'is_foggy' in df.columns: \n",
    "     df['is_foggy'] = df['is_foggy'].fillna(-999)\n",
    "\n",
    "known_non_numeric_cols = ['time', 'pv_id', 'location_cluster', 'climate_cluster'] # (climate_cluster 추가)\n",
    "cols_to_fill = [col for col in df.columns if col not in known_non_numeric_cols]\n",
    "\n",
    "df[cols_to_fill] = df[cols_to_fill].fillna(-999)\n",
    "\n",
    "# (location_cluster와 climate_cluster의 NaN을 -999 카테고리로 채움)\n",
    "for col in ['location_cluster', 'climate_cluster']:\n",
    "    if df[col].isnull().any():\n",
    "        print(f\"'{col}'의 NaN을 '-999' 카테고리로 채웁니다.\")\n",
    "        if -999 not in df[col].cat.categories:\n",
    "             df[col] = df[col].cat.add_categories([-999])\n",
    "        df[col] = df[col].fillna(-999)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# --- 메모리 최적화 ---\n",
    "print(\"모든 float64 칼럼을 float32로 강제 변환하여 메모리 사용량을 절반으로 줄입니다...\")\n",
    "numeric_cols = [col for col in df.columns if col not in known_non_numeric_cols]\n",
    "float64_cols = [col for col in numeric_cols if df[col].dtype == 'float64']\n",
    "for col in float64_cols:\n",
    "    df[col] = df[col].astype('float32')\n",
    "print(f\"{len(float64_cols)}개 칼럼을 float32로 변환 완료.\")\n",
    "gc.collect()\n",
    "\n",
    "# --- 저장 ---\n",
    "print(\"중간 처리된 데이터를 'processed_test.feather' 파일로 저장합니다...\")\n",
    "df.to_feather('processed_test.feather')\n",
    "print(\"저장 완료.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
