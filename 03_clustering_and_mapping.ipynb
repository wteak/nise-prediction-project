{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib # 모델 저장/로드용\n",
    "\n",
    "# [Legacy] 2단계 군집화(Clustering) 및 정적 맵핑 시도\n",
    "# 특이사항: 최적의 K를 찾는 튜닝 과정 없이, 직관적으로 개수를 설정함 (한계점)\n",
    "\n",
    "# --- 1. 데이터 로드 ---\n",
    "print(\"데이터 로드 중...\")\n",
    "train = pd.read_feather('1차_train.feather')\n",
    "test = pd.read_feather('1차_test.feather')\n",
    "\n",
    "# --- 2. 물리적 특성 칼럼 생성 (Train/Test 공통) ---\n",
    "print(\"물리적 특성(포화수증기압, 일교차 등) 변수 생성 중...\")\n",
    "\n",
    "def create_physics_features(df):\n",
    "    # 1. 포화 수증기압차 (Saturation Deficit)\n",
    "    # (기온과 이슬점의 차이로 건조한 정도를 나타냄)\n",
    "    df['saturation_deficit'] = df['temp_a'] - df['dew_point']\n",
    "    \n",
    "    # 2. 일교차 (Diurnal Temp Range)\n",
    "    df['diurnal_temp_range'] = df['temp_max'] - df['temp_min']\n",
    "    \n",
    "    # 3. 태양 노출 계수 (체감온도 - 그늘체감온도)\n",
    "    df['sun_exposure'] = df['real_feel_temp'] - df['real_feel_temp_shade']\n",
    "    \n",
    "    # 4. 안개 여부 (시정 1km 미만)\n",
    "    df['is_foggy'] = (df['vis'] < 1).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_physics_features(train)\n",
    "test = create_physics_features(test)\n",
    "print(\"물리 변수 생성 완료.\")\n",
    "\n",
    "# --- 3. 프로필 기반 통계 추출 (Train 기준) ---\n",
    "print(\"Train 데이터 기준으로 발전소별 기후 프로필 생성...\")\n",
    "# (주의: Test 데이터의 정보는 사용하지 않음 - Data Leakage 방지)\n",
    "\n",
    "pv_id_stats = train.groupby('pv_id')[['temp_a', 'humidity', 'wind_spd_a', 'pressure', 'vis']].mean().reset_index()\n",
    "pv_id_stats.rename(columns={\n",
    "    'temp_a': 'avg_temp', 'humidity': 'avg_humidity', \n",
    "    'wind_spd_a': 'avg_wind', 'pressure': 'avg_pressure', 'vis': 'avg_vis'\n",
    "}, inplace=True)\n",
    "\n",
    "# Train에 병합\n",
    "train_loc = train[['pv_id', 'coord1', 'coord2']].drop_duplicates(subset=['pv_id'])\n",
    "train_loc = pd.merge(train_loc, pv_id_stats, on='pv_id', how='left').fillna(0)\n",
    "\n",
    "# --- 4. 이중 군집화 학습 (Fitting) ---\n",
    "print(\"군집화 모델 학습 시작 (K값 튜닝 없이 직관적으로 설정함)...\")\n",
    "\n",
    "# [1] 위치 군집 (Location Cluster)\n",
    "# 설정 의도: 미세한 지형 차이를 반영하기 위해 80개로 잘게 쪼갬\n",
    "# 한계: Elbow Method 같은 최적화 과정 없이 임의로 80개 설정\n",
    "loc_features = ['coord1', 'coord2']\n",
    "scaler_loc = StandardScaler()\n",
    "train_scaled_loc = scaler_loc.fit_transform(train_loc[loc_features])\n",
    "\n",
    "kmeans_loc = KMeans(n_clusters=80, random_state=42) # 튜닝 없이 80개 고정\n",
    "train_loc['cluster_loc'] = kmeans_loc.fit_predict(train_scaled_loc)\n",
    "\n",
    "# [2] 기후 군집 (Climate Cluster)\n",
    "# 설정 의도: 날씨 패턴은 지역보다 넓으므로 20개로 설정\n",
    "clim_features = ['avg_temp', 'avg_humidity', 'avg_wind', 'avg_pressure', 'avg_vis']\n",
    "scaler_cli = StandardScaler()\n",
    "train_scaled_cli = scaler_cli.fit_transform(train_loc[clim_features])\n",
    "\n",
    "kmeans_cli = KMeans(n_clusters=20, random_state=42) # 튜닝 없이 20개 고정\n",
    "train_loc['cluster_cli'] = kmeans_cli.fit_predict(train_scaled_cli)\n",
    "\n",
    "# 모델 및 스케일러 저장 (나중에 Test 파일 생성에 쓰기 위해)\n",
    "print(\"모델 저장 중...\")\n",
    "joblib.dump(scaler_loc, 'scaler_loc.pkl')\n",
    "joblib.dump(kmeans_loc, 'kmeans_loc.pkl')\n",
    "joblib.dump(scaler_cli, 'scaler_cli.pkl')\n",
    "joblib.dump(kmeans_cli, 'kmeans_cli.pkl')\n",
    "\n",
    "# --- 5. Test 데이터에 적용 (Transform & Predict) ---\n",
    "print(\"저장된 모델을 불러와 Test 데이터에 군집 적용...\")\n",
    "\n",
    "# Test 데이터의 고유 위치/ID 추출\n",
    "test_loc = test[['pv_id', 'coord1', 'coord2']].drop_duplicates(subset=['pv_id'])\n",
    "\n",
    "# (1) 위치 군집 적용\n",
    "# 저장해둔 Scaler와 KMeans 모델을 사용하여 Test 데이터의 군집 예측\n",
    "test_scaled_loc = scaler_loc.transform(test_loc[loc_features])\n",
    "test_loc['cluster_loc'] = kmeans_loc.predict(test_scaled_loc)\n",
    "\n",
    "# (2) 기후 군집 적용\n",
    "# 기후 정보는 Train에서 만든 통계(pv_id_stats)를 pv_id 기준으로 매핑(Map)\n",
    "test_loc = pd.merge(test_loc, pv_id_stats, on='pv_id', how='left').fillna(0)\n",
    "test_scaled_cli = scaler_cli.transform(test_loc[clim_features])\n",
    "test_loc['cluster_cli'] = kmeans_cli.predict(test_scaled_cli)\n",
    "\n",
    "# --- 6. 결과를 원본 데이터에 매핑 ---\n",
    "print(\"군집 결과를 원본 Train/Test 데이터에 병합...\")\n",
    "\n",
    "# 맵(Map) 생성\n",
    "loc_map = dict(zip(test_loc['pv_id'], test_loc['cluster_loc']))\n",
    "cli_map = dict(zip(test_loc['pv_id'], test_loc['cluster_cli']))\n",
    "\n",
    "# Train 적용\n",
    "train['location_cluster'] = train['pv_id'].map(loc_map)\n",
    "train['climate_cluster'] = train['pv_id'].map(cli_map)\n",
    "\n",
    "# Test 적용\n",
    "test['location_cluster'] = test['pv_id'].map(loc_map)\n",
    "test['climate_cluster'] = test['pv_id'].map(cli_map)\n",
    "\n",
    "print(\"완료. 군집화된 데이터셋 준비됨.\")\n",
    "# (이후 이 데이터로 정적 맵핑(일출몰 시간)을 시도했으나 실패함)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
